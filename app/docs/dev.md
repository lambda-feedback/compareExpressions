# CompareExpressions
This function utilises the [`SymPy`](https://docs.sympy.org/latest/index.html) to provide a maths-aware evaluation of a learner's response.

## Evaluation function

The main evaluation function is found in `evaluation.py` as has the following signature:

`evaluation_function(response : str, answer : str, params: dict, include_test_data=False : bool) -> dict`

### Input

This is the function that should be called to evaluate a response expression. 
- `response` is the response expression submitted by the learner
- `answer` is a reference expression provided by the task author
- `params` is a dictionary with optional parameters, for available parameters and their intended use, see the user documentation
- `include_test_data` is a boolean that controls whether some extra data useful for testing or debugging is returned

### Output

The function returns result dictionary with the following fields:
- `is_correct` is a boolean value that indicates whether the response is considered correct or not
- `feedback` is a string that provides information about what the evaluation function found when evaluating the response that is intended to be shown to the learner
- `tags` is a list of strings that encode some information about what the evaluation function has found out about the response, more consistent across similar tasks than the string output in feedback

The returned dictionary will be referred to as the `result` in this documentation.

### Overview
The overall flow of the evaluation procedure can be described as follows:

1. The function uses the parameters given in `params` to determine the context of the evaluation. What context means will be discussed in more detail in section TODO: Add section name here.
2. After the context is determined the response, answer and criteria (either supplied via `params` or from the context) are analysed an necessary information is stored for future use in a dictionary with frozen valuues, i.e. a dictionary where new items can be added but existing items cannot be changed.
3. The feedback generating procedure supplied by the context is used to generate feedback based on the contents of the frozen value dictionary.
4. If all criteria are found to be satisfied the response is considered correct, i.e. the `is_correct` field in the result is set to true and the feedback string and list of tags generated by the feedback generation procedure are added to their respective fields.

**TODO** Describe what further information is supplied when `include_test_data` is set to true.

### Context

The context is a data structure that contains at least the following seven pieces of information:
- `default_parameters` A dictionary where the keys are parameter names and the values are the default values that the evaluation function will use unless another value is provided together with the response. The only required field is the 
- `expression_parse` function that parses expressions (i.e. the `response` and `answer` inputs) into the form used by the feedback generation procedure.
- `expression_preprocess` function that performs string manipulations that makes ensures that correctly written input expressions follows the conventions expected by `expression_parse`.
- `expression_preview` is a function that generates a string that can be turned into a human-readable representation of how the evaluation function interpreted the response.
- `feedback_procedure_generator` function that generates a function for each criteria that can be used to evaluate if the criteria is satisfied or not. The output from this function should be a list of tags that the feedback string generator can use to produce human readable feedback.
- `feedback_string_generator` function that takes tags and outputs human readable feedback strings.
- `generate_criteria_parser` function that generates a parser that can be used to turn the criteria (given in string form) into a form that the feedback generation procedure can use to determine if they are correct or not.

The context can also contain other fields if necessary.

**Remark:** The current implementation uses a dictionary rather than a dedicated class for ease of iteration during the initial development phase.

There are currently two different contexts:
- `symbolic` Handles comparisons of various symbolic expressions. Defined in `context\symbolic.py`.
- `physical_quantity` Handles comparisons of expressions involving units. Defined in `context\physical_quantity.py`.

**Remark:** Handwritten expressions are sent as latex, which requires extra preprocessing before the right context can be determined in some cases. It should be considered whether a new context, perhaps called `handwritten`, should be created for this purpose.

**TODO** Describe currently available contexts
#### `symbolic` - Comparison of symbolic expressions

**Remark:** The `symbolic` context should probably be split into several smaller contexts, the following subdivision is suggested:
- `numerical`: Comparison of expressions that can be evaluated to numerical values (e.g. expressions that are already numerical values or expressions only containing constants). Focuses on identifying if numerical values are greater than, less than, proportional to the expected answer or similar.
- `symbolic`: Comparison of symbolic expressions that cannot be reduced to numerical values.
- `equality`: Comparison of mathematical equalities (with the extra complexities that come with equivalence of equalities compared to equality of expressions).
- `inequality`: Same as `equality` except for mathematical inequalities (which will require different choices when it comes to what can be considered equivalence). It might be appropriate to combine `equality` and `inequality` into one context (called `statements` or similar).
- `collection`: Comparison of collections (e.g. sets, lists or intervals of the number line). Likely to consist mostly of code for handling comparison of individual elements using the other contexts, and configuring what counts as equivalence between different collections.

#### `physical_quantity` - Comparison of expressions that involve units

#### Code shared between different contexts

### Criteria

**TODO** Describe currently available criteria

#### Criteria command and grammar

#### Examples of commonly used criteria

### Feedback generation

### Returning final results